{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicocampo/CNN_prova/blob/Prime_modifiche/Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrpN8XfwiOuY"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX2l9UzukeAj"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "from skimage.io import imread, imshow\r\n",
        "from skimage import img_as_float\r\n",
        "from skimage.restoration import denoise_wavelet\r\n",
        "from PIL import Image\r\n",
        "import pywt\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import numpy as np\r\n",
        "import logging\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCDSePVxkUmu"
      },
      "source": [
        "PATH = 'gdrive/MyDrive/IMAGES/Mammography_micro'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beBBNjLm0A5F"
      },
      "source": [
        "#Two and three levels denoise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyZg3ss77rS5"
      },
      "source": [
        "def twolvldenoiseddwt(myim, wavelet):\r\n",
        "    \"\"\" This function decompose the original image with a Discrete Wavelet Transformation\r\n",
        "        using the desired wavelet family up to the third level. It keeps all the details\r\n",
        "        coefficient and mask the resulted approximated image in order to enhance the\r\n",
        "        visibility of all the details.\r\n",
        "    \"\"\"\r\n",
        "    myim = img_as_float(myim)\r\n",
        "    myim_denoised = denoise_wavelet(myim, method='BayesShrink', mode='soft', rescale_sigma='True')\r\n",
        "\r\n",
        "    level = 2\r\n",
        "    # mode = 'periodization' \r\n",
        "\r\n",
        "    # Here I get my approximated image and the relative coefficients\r\n",
        "    cA, (cH2, cV2, cD2), (cH1, cV1, cD1) = pywt.wavedec2(myim_denoised, wavelet, level=level)\r\n",
        "\r\n",
        "    \"\"\" Now, I get the standard deviation for each matrix (image and coefficients).\r\n",
        "        The std will act as a treshold so that if abs(value) < 0. --> value = 0.\r\n",
        "                                             elif abs(value) > 0. --> value = value\r\n",
        "    \"\"\" \r\n",
        "    mult_val = 1.\r\n",
        "\r\n",
        "    ncA = np.zeros_like(cA)\r\n",
        "\r\n",
        "    std10 = np.std(cH1)*mult_val\r\n",
        "    std11 = np.std(cV1)*mult_val\r\n",
        "    std12 = np.std(cD1)*mult_val\r\n",
        "\r\n",
        "    ncH1 = pywt.threshold(cH1, std10, mode = 'hard', substitute = 0.)\r\n",
        "    ncV1 = pywt.threshold(cV1, std11, mode = 'hard', substitute = 0.)\r\n",
        "    ncD1 = pywt.threshold(cD1, std12, mode = 'hard', substitute = 0.)\r\n",
        "\r\n",
        "    std20 = np.std(cH2)*mult_val\r\n",
        "    std21 = np.std(cV2)*mult_val\r\n",
        "    std22 = np.std(cD2)*mult_val\r\n",
        "\r\n",
        "    ncH2 = pywt.threshold(cH2, std20, mode = 'hard', substitute = 0.)\r\n",
        "    ncV2 = pywt.threshold(cV2, std21, mode = 'hard', substitute = 0.)\r\n",
        "    ncD2 = pywt.threshold(cD2, std22, mode = 'hard', substitute = 0.)\r\n",
        "\r\n",
        "    \"\"\" To let things be more readable I define new_coeff,\r\n",
        "        this is just so that waverec2 (the function needed to reconstruct\r\n",
        "        the image from a set of given coefficient) can do what it does.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    new_coeff = ncA, (ncH2, ncV2, ncD2), (ncH1, ncV1, ncD1) \r\n",
        "\r\n",
        "    mynewim = pywt.waverec2(new_coeff, wavelet)\r\n",
        "    mynewim = pywt.threshold(mynewim, 0., mode = 'greater', substitute = 0.)\r\n",
        "\r\n",
        "    return mynewim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AXUMqyylcqL"
      },
      "source": [
        "def threelvldenoiseddwt(myim, wavelet):\r\n",
        "    \"\"\" This function decompose the original image with a Discrete Wavelet Transformation\r\n",
        "        using the desired wavelet family up to the third level. It keeps all the details\r\n",
        "        coefficient and mask the resulted approximated image in order to enhance the\r\n",
        "        visibility of all the details.\r\n",
        "    \"\"\"\r\n",
        "    myim = img_as_float(myim)\r\n",
        "    myim_denoised = denoise_wavelet(myim, method='BayesShrink', mode='soft', rescale_sigma='True')\r\n",
        "\r\n",
        "    level = 3\r\n",
        "    # mode = 'periodization' \r\n",
        "\r\n",
        "    # Here I get my approximated image and the relative coefficients\r\n",
        "    cA, (cH3, cV3, cD3), (cH2, cV2, cD2), (cH1, cV1, cD1) = pywt.wavedec2(myim_denoised, wavelet, level=level)\r\n",
        "\r\n",
        "    \"\"\" Now, I get the standard deviation for each matrix (image and coefficients).\r\n",
        "        The std will act as a treshold so that if abs(value) < 0. --> value = 0.\r\n",
        "                                             elif abs(value) > 0. --> value = value\r\n",
        "    \"\"\" \r\n",
        "    mult_val = 1.\r\n",
        "\r\n",
        "    ncA = np.zeros_like(cA)\r\n",
        "\r\n",
        "    std10 = np.std(cH1)*mult_val\r\n",
        "    std11 = np.std(cV1)*mult_val\r\n",
        "    std12 = np.std(cD1)*mult_val\r\n",
        "\r\n",
        "    ncH1 = pywt.threshold(cH1, std10, mode = 'hard', substitute = 0.)\r\n",
        "    ncV1 = pywt.threshold(cV1, std11, mode = 'hard', substitute = 0.)\r\n",
        "    ncD1 = pywt.threshold(cD1, std12, mode = 'hard', substitute = 0.)\r\n",
        "\r\n",
        "    std20 = np.std(cH2)*mult_val\r\n",
        "    std21 = np.std(cV2)*mult_val\r\n",
        "    std22 = np.std(cD2)*mult_val\r\n",
        "\r\n",
        "    ncH2 = pywt.threshold(cH2, std20, mode = 'hard', substitute = 0.)\r\n",
        "    ncV2 = pywt.threshold(cV2, std21, mode = 'hard', substitute = 0.)\r\n",
        "    ncD2 = pywt.threshold(cD2, std22, mode = 'hard', substitute = 0.)\r\n",
        "    \r\n",
        "    std30 = np.std(cH3)*mult_val\r\n",
        "    std31 = np.std(cV3)*mult_val\r\n",
        "    std32 = np.std(cD3)*mult_val\r\n",
        "\r\n",
        "    ncH3 = pywt.threshold(cH3, std30, mode = 'hard', substitute = 0.)\r\n",
        "    ncV3 = pywt.threshold(cV3, std31, mode = 'hard', substitute = 0.)\r\n",
        "    ncD3 = pywt.threshold(cD3, std32, mode = 'hard', substitute = 0.)\r\n",
        "\r\n",
        "    \"\"\" To let things be more readable I define new_coeff,\r\n",
        "        this is just so that waverec2 (the function needed to reconstruct\r\n",
        "        the image from a set of given coefficient) can do what it does.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    new_coeff = ncA, (ncH3, ncV3, ncD3), (ncH2, ncV2, ncD2), (ncH1, ncV1, ncD1) \r\n",
        "\r\n",
        "    mynewim = pywt.waverec2(new_coeff, wavelet)\r\n",
        "    mynewim = pywt.threshold(mynewim, 0., mode = 'greater', substitute = 0.)\r\n",
        "\r\n",
        "    return mynewim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vociCFEY0O3f"
      },
      "source": [
        "#Reading images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McKFOONMxZJL"
      },
      "source": [
        "import multiprocessing as mp\r\n",
        "\r\n",
        "def read_img(image_path):\r\n",
        "  '''Takes as input the path to the image folder and \r\n",
        "  returns the numpy array of images and label found in that folder'''\r\n",
        "\r\n",
        "  #Creating a list of all image names found in image_path\r\n",
        "  fnames = glob.glob(os.path.join(image_path, '*.pgm'))\r\n",
        "\r\n",
        "  #Defining 4 sub-processes and apply imread to all the images found previously\r\n",
        "  #(imread reads images in pgm format)\r\n",
        "  pool = mp.Pool(processes=4)\r\n",
        "  results = pool.map_async(imread, fnames)\r\n",
        "\r\n",
        "  #Get the list of images and convert to numpy array\r\n",
        "  x = results.get()\r\n",
        "  x_np = np.array(x, dtype='float32')[..., np.newaxis]/255\r\n",
        "\r\n",
        "  logger.info('Num images found in %s: %d',image_path, len(x_np))\r\n",
        "\r\n",
        "  #Create a list of corrisponding labels and conver it to numpy array\r\n",
        "  label = os.path.basename(image_path)\r\n",
        "  y = [int(label)] * len(x_np)\r\n",
        "  y_np = np.array(y)\r\n",
        "\r\n",
        "  \r\n",
        "  return x_np, y_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egjVnE321Jan"
      },
      "source": [
        "'''Read images using read_img function'''\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "#Define the path to the sub-folder of Train images folder containing \"normal\" breast mammograms\r\n",
        "image_path = os.path.join(PATH, 'Train/0')\r\n",
        "#Create the test images and labels array with read_img function\r\n",
        "x0_train, y0_train = read_img(image_path)\r\n",
        "\r\n",
        "\r\n",
        "#Define the path to the sub-folder of Train images folder containing breast mammograms with microcalcifications\r\n",
        "image_path = os.path.join(PATH, 'Train/1')\r\n",
        "#Create the test images and labels array with read_img function\r\n",
        "x1_train, y1_train = read_img(image_path)\r\n",
        "\r\n",
        "#Create an array with both normal and sick images and labels\r\n",
        "x_train = np.concatenate((x0_train, x1_train), axis = 0)\r\n",
        "y_train = np.concatenate((y0_train, y1_train))\r\n",
        "\r\n",
        "#Processing images\r\n",
        "proc_x_train = []\r\n",
        "for image in enumerate(x_train):\r\n",
        "  processedimage = threelvldenoiseddwt(image, 'db5')\r\n",
        "  proc_x_train.append(processedimage)\r\n",
        "\r\n",
        "proc_x_train = np.array(processed_x_train, dtype='float32')[..., np.newaxis]/255\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Doing the same of previous lines, on Test folder\r\n",
        "image_path = os.path.join(PATH, 'Test/0')\r\n",
        "x0_test, y0_test = read_img(image_path)\r\n",
        "\r\n",
        "image_path = os.path.join(PATH, 'Test/1')\r\n",
        "x1_test, y1_test = read_img(image_path)\r\n",
        "\r\n",
        "x_test = np.concatenate((x0_test, x1_test), axis = 0)\r\n",
        "y_test = np.concatenate((y0_test, y1_test))\r\n",
        "\r\n",
        "proc_x_test = []\r\n",
        "for image in enumerate(x_test):\r\n",
        "  processedimage = threelvldenoiseddwt(image, 'db5')\r\n",
        "  proc_x_test.append(processedimage)\r\n",
        "\r\n",
        "proc_x_test = np.array(processed_x_test, dtype='float32')[..., np.newaxis]/255\r\n",
        "\r\n",
        "\r\n",
        "#Print the total number of images found.\r\n",
        "print(f'There are {len(x_train)} train images and {len(x_test)} test images')\r\n",
        "\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "logger.debug('Done in %.2f s', elapsed_time)\r\n",
        "\r\n",
        "print(f'\\nx_test_processed shape = {proc_x_test.shape} <-- (number of images, width, height)\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VLFSje7gBMS"
      },
      "source": [
        "# Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak9GK-n-VT6O"
      },
      "source": [
        "from keras.layers import Dense, Flatten, BatchNormalization\r\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpTziKPzeh8_"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Flatten(), \r\n",
        "    Dense(102,  activation = 'relu'), \r\n",
        "    BatchNormalization(),\r\n",
        "    Dense(32, activation = 'relu'), \r\n",
        "    BatchNormalization(),\r\n",
        "\r\n",
        "    Dense(1, activation = 'sigmoid')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkz9ADsYgLx4"
      },
      "source": [
        "Compile and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih8_BZlEgsd8"
      },
      "source": [
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer=Adam(learning_rate = 0.0005),\r\n",
        "    loss='binary_crossentropy',\r\n",
        "    metrics=['binary_accuracy'],\r\n",
        ")\r\n",
        "\r\n",
        "history = model.fit(\r\n",
        "    x_train, y_train,\r\n",
        "    validation_split = 0.25, \r\n",
        "    epochs=50,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa8RizVKBjHy"
      },
      "source": [
        "'''Visualize loss, val_loss, accuracy and val_accuracy obtanined during the train''' \r\n",
        "plt.figure(1)\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss and val_loss')\r\n",
        "\r\n",
        "plt.figure(2)\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Accuracy and val_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}