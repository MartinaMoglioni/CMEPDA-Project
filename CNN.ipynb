{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicocampo/CNN_prova/blob/Prime_modifiche/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfPNt06nZRfC"
      },
      "source": [
        "Mounting Google Drive Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycQRMl2Bg4Me"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNUU6BXG_-Ia"
      },
      "source": [
        "#Setting a personal logger and a streamHandler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJpPtAOPv1D2"
      },
      "source": [
        "import time\r\n",
        "import logging\r\n",
        "\r\n",
        "#Setting a logger and a logging level\r\n",
        "logger = logging.getLogger('Mylogger')\r\n",
        "logger.setLevel(logging.DEBUG)\r\n",
        "#Setting an handler to send logging output\r\n",
        "ch = logging.StreamHandler()\r\n",
        "ch.setLevel(logging.DEBUG)\r\n",
        "#Set the format of every log message printing the name of logger, logging level and the message.\r\n",
        "formatter = logging.Formatter('%(name)s (%(levelname)s): %(message)s')\r\n",
        "ch.setFormatter(formatter)\r\n",
        "#Add the specified handler to this logger.\r\n",
        "logger.addHandler(ch)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqw3aYF1gDFD"
      },
      "source": [
        "# Read and visualize the original dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efnimlHHCbZ6"
      },
      "source": [
        "##Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqCZ72z2gCIH"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "import os\n",
        "import glob\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkOspN9xPlg8"
      },
      "source": [
        "PATH = 'gdrive/MyDrive/IMAGES/Mammography_micro'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKkkzEYlMqP"
      },
      "source": [
        "Defining a functionro read every images and labels and put them into an array\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bVKQicJt1gi"
      },
      "source": [
        "import multiprocessing as mp\r\n",
        "\r\n",
        "def read_img(image_path):\r\n",
        "  '''Takes as input the path to the image folder and \r\n",
        "  returns the numpy array of images and label found in that folder'''\r\n",
        "\r\n",
        "  #Creating a list of all image names found in image_path\r\n",
        "  fnames = glob.glob(os.path.join(image_path, '*.pgm'))\r\n",
        "\r\n",
        "  #Defining 4 sub-processes and apply imread to all the images found previously\r\n",
        "  #(imread reads images in pgm format)\r\n",
        "  pool = mp.Pool(processes=4)\r\n",
        "  results = pool.map_async(imread, fnames)\r\n",
        "\r\n",
        "  #Get the list of images and convert to numpy array\r\n",
        "  x = results.get()\r\n",
        "  x_np = np.array(x, dtype='float32')[..., np.newaxis]/255\r\n",
        "\r\n",
        "  logger.info('Num images found in %s: %d',image_path, len(x_np))\r\n",
        "\r\n",
        "  #Create a list of corrisponding labels and conver it to numpy array\r\n",
        "  label = os.path.basename(image_path)\r\n",
        "  y = [int(label)] * len(x_np)\r\n",
        "  y_np = np.array(y)\r\n",
        "\r\n",
        "  \r\n",
        "  return x_np, y_np\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAREAlnsKhWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7baa77f-64e7-43ab-f33b-dfc4c4b4c9a9"
      },
      "source": [
        "start_time = time.time()\r\n",
        "\r\n",
        "#Define the path to the sub-folder of Train images folder containing \"normal\" breast mammograms\r\n",
        "image_path = os.path.join(PATH, 'Train/0')\r\n",
        "#Create the test images and labels array with read_img function\r\n",
        "x0_train, y0_train = read_img(image_path)\r\n",
        "\r\n",
        "\r\n",
        "#Define the path to the sub-folder of Train images folder containing breast mammograms with microcalcifications\r\n",
        "image_path = os.path.join(PATH, 'Train/1')\r\n",
        "#Create the test images and labels array with read_img function\r\n",
        "x1_train, y1_train = read_img(image_path)\r\n",
        "\r\n",
        "#Create an array with both normal and sick images and labels\r\n",
        "x_train = np.concatenate((x0_train, x1_train), axis = 0)\r\n",
        "y_train = np.concatenate((y0_train, y1_train))\r\n",
        "\r\n",
        "#Doing the same of previous lines, on Test folder\r\n",
        "image_path = os.path.join(PATH, 'Test/0')\r\n",
        "x0_test, y0_test = read_img(image_path)\r\n",
        "\r\n",
        "image_path = os.path.join(PATH, 'Test/1')\r\n",
        "x1_test, y1_test = read_img(image_path)\r\n",
        "\r\n",
        "x_test = np.concatenate((x0_test, x1_test), axis = 0)\r\n",
        "y_test = np.concatenate((y0_test, y1_test))\r\n",
        "\r\n",
        "#Print the total number of images found.\r\n",
        "print(f'There are {len(x_train)} train images and {len(x_test)} test images')\r\n",
        "\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "logger.debug('Done in %.2f s', elapsed_time)\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mylogger (INFO): Num images found in gdrive/MyDrive/IMAGES/Mammography_micro/Train/0: 209\n",
            "Mylogger (INFO): Num images found in gdrive/MyDrive/IMAGES/Mammography_micro/Train/1: 187\n",
            "Mylogger (INFO): Num images found in gdrive/MyDrive/IMAGES/Mammography_micro/Test/0: 205\n",
            "Mylogger (INFO): Num images found in gdrive/MyDrive/IMAGES/Mammography_micro/Test/1: 196\n",
            "Mylogger (DEBUG): Done in 1.44 s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "There are 396 train images and 401 test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZPx6CGyBdpG"
      },
      "source": [
        "Create a single array with both train and test images and an array containing all labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5zh7TpIBcVp"
      },
      "source": [
        "# Merge train and test in a single array n-dim\r\n",
        "X_tot = np.concatenate((x_train, x_test), axis=0)\r\n",
        "Y_tot = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1BAtPrtt7Fm"
      },
      "source": [
        "***Visualize some images***\r\n",
        "\r\n",
        "Visualize n random train images and n random test images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfyUHHdW3Pa_"
      },
      "source": [
        "import random \r\n",
        "\r\n",
        "#defining the number of images to visualize\r\n",
        "n = 10\r\n",
        "\r\n",
        "\r\n",
        "#Defining the number or rows and columns of the subplots based on the parity of n\r\n",
        "if n % 2 == 0:\r\n",
        "  n_rows = n/2\r\n",
        "  n_cols = n/2\r\n",
        "else: \r\n",
        "  n_rows = int(round(n/2))\r\n",
        "  n_cols = int(round(n/2)) +1\r\n",
        "\r\n",
        "#Create the main figure and the subfigures of training images\r\n",
        "plt.figure(1, figsize = (15, 15))\r\n",
        "plt.suptitle('Train images')\r\n",
        "for i in range(1, n+1):\r\n",
        "  #Choose a random index among x_train number of images\r\n",
        "  r = random.randrange(0, len(x_train))\r\n",
        "  #Plotting the corrisponding image\r\n",
        "  Im = x_train[r].squeeze()\r\n",
        "  plt.subplot(n_rows, n_cols, i)\r\n",
        "  plt.imshow(Im, cmap = 'gray')\r\n",
        "  plt.axis('off')\r\n",
        "  plt.title(f'{y_train[r]}')\r\n",
        "\r\n",
        "#Create the main figure and the subfigures of test images\r\n",
        "plt.figure(2, figsize = (15, 15))\r\n",
        "plt.suptitle('Test images')\r\n",
        "for i in range(1, n+1):\r\n",
        "  r = random.randrange(0, len(x_test))\r\n",
        "  Im = x_test[r].squeeze()\r\n",
        "  plt.subplot(n_rows, n_cols, i)\r\n",
        "  plt.imshow(Im, cmap = 'gray')\r\n",
        "  plt.axis('off')\r\n",
        "  plt.title(f'{y_test[r]}')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBkLQzhsmYaJ"
      },
      "source": [
        "#Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xang6C1lUht"
      },
      "source": [
        "##Convert all 'pgm' images format to 'png' format\r\n",
        "(needed to run ImageDataGenerator)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsWgaT6LmebC"
      },
      "source": [
        "import PIL\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re8kga5lmeMA"
      },
      "source": [
        "def convert_to_png(fname, dest_folder):\r\n",
        "  #Create a new folder to put converted images in\r\n",
        "  if not os.path.exists(dest_folder):\r\n",
        "    os.makedirs(dest_folder)\r\n",
        "    \r\n",
        "  logger.debug('converting %s', fname)\r\n",
        "  #Change the name of the filename to png extension\r\n",
        "  dest_fname = os.path.basename(fname).replace('.pgm', '.png')\r\n",
        "  #Define the destination file path\r\n",
        "  dest_fname = os.path.join(dest_folder, dest_fname)\r\n",
        "  #Convert the image to grayscale and save it\r\n",
        "  PIL.Image.open(fname).convert('L').save(dest_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XUCFASbmjLH"
      },
      "source": [
        "for data_path in [os.path.join(PATH, \"Train\"), os.path.join(PATH, \"Test\")]:\r\n",
        "  for path, folders, fnames in os.walk(data_path):\r\n",
        "    #Using convert_to_png function to every filename\r\n",
        "    for fname in fnames:\r\n",
        "      abs_path = os.path.join(path, fname)\r\n",
        "      #Set the folder for png images at the same path of original pgm images\r\n",
        "      dest_folder = path.replace('Train', 'Train_png').replace('Test', 'Test_png')\r\n",
        "      convert_to_png(abs_path, dest_folder)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm0582HRmr_h"
      },
      "source": [
        "##Data augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLXrCayXmrV3"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SayDNbnm3Fr"
      },
      "source": [
        "*  **ImageDataGenerator**\r\n",
        "\r\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\r\n",
        "\r\n",
        "*  **flow_from_directory**\r\n",
        "\r\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I49kI5enm4C_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2ac6f6-b330-4cf0-9f92-2e9911eb0d1e"
      },
      "source": [
        "path_to_png_data = os.path.join(PATH, \"Train_png\")\r\n",
        "#Define the shape of the images\r\n",
        "img_width, img_height = (60, 60)\r\n",
        "\r\n",
        "#Setting the fraction of image to use during training and validation\r\n",
        "aug_validation_split = 0.3\r\n",
        "\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    '''Defining the operations to be randomly done to every input image''' \r\n",
        "        rotation_range=45,  #[Degrees] \r\n",
        "        height_shift_range=0.2,\r\n",
        "        zoom_range=0.2,  \r\n",
        "        rescale=1./255,  #Rescale every pixel to have a value between 0 and 1\r\n",
        "        shear_range=0.2, #Stretches the image \r\n",
        "        fill_mode='reflect',#Fill blank spaces reflecting the images \r\n",
        "        validation_split = validation_split)  \r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_gen = train_datagen.flow_from_directory(\r\n",
        "    '''\r\n",
        "    Takes as input the destination folder path and generates\r\n",
        "    batches of images giving as output an iterator (x, y) \r\n",
        "    where y is the iterator over the labels and x over the images.\r\n",
        "    '''\r\n",
        "    path_to_png_data,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    color_mode='grayscale', \r\n",
        "    class_mode='binary',#Define the type of labels array: binary = 1D \r\n",
        "    subset='training') #Set the corrisponding batch of image to be used as training or validation.\r\n",
        "\r\n",
        "\r\n",
        "val_gen = train_datagen.flow_from_directory(\r\n",
        "    path_to_png_data,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    color_mode='grayscale',\r\n",
        "    class_mode='binary',\r\n",
        "    subset='validation')\r\n",
        "\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 278 images belonging to 2 classes.\n",
            "Found 118 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blz5VJ8pajXz"
      },
      "source": [
        "# Defining a CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3-tiYKxLeWa"
      },
      "source": [
        "Keras layers documentation: https://keras.io/api/layers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7plXV2WyaoGt"
      },
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dense, Flatten, InputLayer, Activation, Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBloTVdsaewM"
      },
      "source": [
        "def make_model(shape=(60, 60, 1)):\n",
        "  ''' Takes as input the shape of images (Default = (60, 60, 1) is the shape\n",
        "   of the dataset) and return the keras.model class.'''\n",
        "  model = Sequential([\n",
        "                      \n",
        "      Conv2D(50, (5,5), padding='same', input_shape=shape),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPool2D((2,2)),\n",
        "      \n",
        "      Conv2D(60, (3,3), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPool2D((2,2)),\n",
        "        \n",
        "      Conv2D(100, (3,3), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "\n",
        "      Conv2D(100, (3,3), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "\n",
        "      Conv2D(50, (4,4), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPool2D(2, 2),\n",
        "\n",
        "      Flatten(), \n",
        "      \n",
        "\n",
        "      Dense(1, activation='sigmoid')\n",
        "      \n",
        "  ])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXt999cLSEeT"
      },
      "source": [
        "#Fit model on original dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlOs39msC6cs"
      },
      "source": [
        "ModelCheckpoint: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUQjwzu90fsX"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "#Set a checkpoint to save weights giving the best performance on val_accuracy \r\n",
        "checkpoint = ModelCheckpoint(\r\n",
        "    \"model-{epoch:02d}-{val_accuracy:.2f}.hdf5\", \r\n",
        "    monitor='val_accuracy', \r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=False,\r\n",
        "    mode='auto', save_freq='epoch')\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHZyPE9vK-mv"
      },
      "source": [
        "Model.compile: https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPh3ewyPn1bR"
      },
      "source": [
        "from keras.optimizers import SGD\r\n",
        "\r\n",
        "'''Define the model and compile it'''\r\n",
        "model = make_model()\r\n",
        "model.compile(optimizer = SGD(lr = 0.001, momentum = 0.9), metrics = 'accuracy', loss='binary_crossentropy')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EgW8Xp8Kquu"
      },
      "source": [
        "Model.fit: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH25BWCqfbGM"
      },
      "source": [
        "'''Training the model using x_train and y_train images and labels and doing a validation split of 30%'''\r\n",
        "\r\n",
        "val_split = 0.3\r\n",
        "\r\n",
        "history = model.fit(x_train, y_train, \r\n",
        "                    validation_split=val_split, \r\n",
        "                    epochs=100, \r\n",
        "                    batch_size=30, \r\n",
        "                    shuffle=True, \r\n",
        "                    callbacks = [checkpoint],\r\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXkkfjdPSsuM"
      },
      "source": [
        "'''Visualize loss, val_loss, accuracy and val_accuracy obtanined during the train''' \r\n",
        "plt.figure(1)\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss and val_loss')\r\n",
        "\r\n",
        "plt.figure(2)\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Accuracy and val_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ConM7Babe9VD"
      },
      "source": [
        "#Saving the model\r\n",
        "model.save(os.path.join(PATH, 'model.hdf5'))\r\n",
        "#Evaluate performances of the model \r\n",
        "#calculating 'loss' and 'metrics' (accuracy in our case)\r\n",
        "model.evaluate(x_test, y_test) \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS3iyYXqoda2"
      },
      "source": [
        "# Fit model on augmented dataset\r\n",
        "\r\n",
        "Similarly to the block above, now the training is performed on augmented dataset. This block can be run indipendently from the previous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avE0zljglFk5"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"model_augmented.{epoch:02d}-{val_accuracy:.2f}.h5\", \n",
        "    monitor='val_accuracy', \n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto', save_freq='epoch')\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7yiPz99j_Fw"
      },
      "source": [
        "'''Defining the model, compiling and training it'''\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = make_model()\n",
        "\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "#Defining the number of images to do training on\n",
        "Tot_train_imgs = len(x_train)\n",
        "#Defining the number of steps to do in each epoch\n",
        "steps_per_epoch = int(Tot_train_imgs * (1- aug_validation_split))\n",
        "#Defining the total number of samples to create for validation\n",
        "validation_steps = int(Tot_train_imgs * aug_validation_split)\n",
        "\n",
        "logger.info('Steps per epoch = %d', steps_per_epoch)\n",
        "logger.info('Val steps = %d', validation_steps)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch = steps_per_epoch // batch_size,\n",
        "        epochs=100,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps= validation_steps // batch_size,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkoLiCT4TX5x"
      },
      "source": [
        "'''Visualize loss, val_loss, accuracy and val_accuracy obtanined during the train''' \r\n",
        "\r\n",
        "plt.figure(1)\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss and val_loss')\r\n",
        "\r\n",
        "plt.figure(2)\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Accuracy and val_accuracy')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7sjHFpGpPtI"
      },
      "source": [
        "'''Saving and evaluating the model'''\r\n",
        "\r\n",
        "model.save(os.path.join(PATH, 'model_augmented.hdf5'))\r\n",
        "\r\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziJxv3y8fYoo"
      },
      "source": [
        "# Comparing the performances of the two trainings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u8dNJW0fLd3"
      },
      "source": [
        "from keras.models import load_model\n",
        "aug_model = load_model(os.path.join(PATH, 'model_augmented.hdf5'))\n",
        "noaug_model = load_model(os.path.join(PATH, 'model.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoMbhMQMf_E9"
      },
      "source": [
        "noaug_model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "aug_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53lAkDPmWmiK"
      },
      "source": [
        "#*Testing model on wavelet-filtered images*\r\n",
        "\r\n",
        "Now the training is performed on wavelet filtered dataset with the same model and optimizer. This block can be run independently from the training blocks above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJA_n59C7jRB"
      },
      "source": [
        "##Define the path and the wavelet type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o26QMFx_Wl_6"
      },
      "source": [
        "PATH = 'gdrive/MyDrive/IMAGES/Mammography_micro/Wavelets'"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plFsvsZnFa33",
        "outputId": "b7b9ba87-6789-4330-eecd-b9e34b043199"
      },
      "source": [
        "#Visualize all wavelet decomposition found in the folder\r\n",
        "print('Wavelet type:')\r\n",
        "for i, wavelet_type in enumerate(os.listdir(PATH)):\r\n",
        "  print(f'{i}. {wavelet_type}')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wavelet type:\n",
            "0. sym2_3levels_nodenoise\n",
            "1. db2_3levels_nodenoise\n",
            "2. db5_4levels_nodenoise\n",
            "3. sym2_3levels_yesdenoise\n",
            "4. db5_4levels_yesdenoise\n",
            "5. db2_3levels_yesdenoise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaA96tzFykbz"
      },
      "source": [
        "#Choose a wavelet type\r\n",
        "wavelet_type = 'db5_4levels_yesdenoise'"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbhjmxEcyrzZ"
      },
      "source": [
        "##Reading the images applying read_img function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHaHYEUdDMi9"
      },
      "source": [
        "#Define the path to the sub-folder of Train images folder containing \"normal\" breast mammograms\r\n",
        "image_path = os.path.join(PATH, wavelet_type,'Train/0')\r\n",
        "#Create the test images and labels array with read_img function\r\n",
        "x0_train, y0_train = read_img(image_path)\r\n",
        "\r\n",
        "\r\n",
        "#Define the path to the sub-folder of Train images folder containing breast mammograms with microcalcifications\r\n",
        "image_path = os.path.join(PATH, wavelet_type,'Train/1')\r\n",
        "#Create the test images and labels array with read_img function\r\n",
        "x1_train, y1_train = read_img(image_path)\r\n",
        "\r\n",
        "#Create an array with both normal and sick images and labels\r\n",
        "x_train = np.concatenate((x0_train, x1_train), axis = 0)\r\n",
        "y_train = np.concatenate((y0_train, y1_train))\r\n",
        "\r\n",
        "#Doing the same of previous lines, on Test folder\r\n",
        "image_path = os.path.join(PATH, wavelet_type, 'Test/0')\r\n",
        "x0_test, y0_test = read_img(image_path)\r\n",
        "\r\n",
        "image_path = os.path.join(PATH,  wavelet_type,'Test/1')\r\n",
        "x1_test, y1_test = read_img(image_path)\r\n",
        "\r\n",
        "x_test = np.concatenate((x0_test, x1_test), axis = 0)\r\n",
        "y_test = np.concatenate((y0_test, y1_test))\r\n",
        "\r\n",
        "#Print the total number of images found.\r\n",
        "print(f'There are {len(x_train)} train images and {len(x_test)} test images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuxDa1eny19p"
      },
      "source": [
        "##Training and eveluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWW6SqE37tJD"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "#Set a checkpoint to save weights giving the best performance on val_accuracy \r\n",
        "checkpoint = ModelCheckpoint(\r\n",
        "    \"model_on_wavelets-{epoch:02d}-{val_accuracy:.2f}.hdf5\", \r\n",
        "    monitor='val_accuracy', \r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=False,\r\n",
        "    mode='auto', save_freq='epoch')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiFC2u1m77iJ"
      },
      "source": [
        "from keras.optimizers import SGD\r\n",
        "\r\n",
        "model = make_model()\r\n",
        "\r\n",
        "model.compile(optimizer = SGD(lr = 0.001, momentum = 0.9), metrics = 'accuracy', loss='binary_crossentropy')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK7nfHZO8CDJ"
      },
      "source": [
        "history = model.fit(x_train, y_train, \r\n",
        "                    validation_split=0.3, \r\n",
        "                    epochs=100, \r\n",
        "                    batch_size=30, \r\n",
        "                    shuffle=True, \r\n",
        "                    callbacks = [checkpoint],\r\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTzaJmL-8Cpt"
      },
      "source": [
        "'''Visualize loss, val_loss, accuracy and val_accuracy obtanined during the train''' \r\n",
        "\r\n",
        "plt.figure(1)\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss and val_loss')\r\n",
        "\r\n",
        "plt.figure(2)\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Accuracy and val_accuracy')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK8MNgnv8Frv"
      },
      "source": [
        "#calculate 'loss' and 'metrics' (accuracy in our case)\r\n",
        "model.evaluate(x_test, y_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZBgQ-PwuSFq"
      },
      "source": [
        "#Implement a cross-validation test\r\n",
        "\r\n",
        "It can be run both for original dataset and for wavelet-filtered dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md5HpjB_uzIJ"
      },
      "source": [
        "from sklearn.model_selection import KFold\r\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD48m6pyP4SI"
      },
      "source": [
        "KFold: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhshIa47uU-x"
      },
      "source": [
        "# Define per-fold accuracy and loss arrays\r\n",
        "acc_per_fold = []\r\n",
        "loss_per_fold = []\r\n",
        "\r\n",
        "#Define the number of folds to split dataset on\r\n",
        "num_folds = 10\r\n",
        "#Defining the function KFold useful to split the dataset\r\n",
        "kfold = KFold(n_splits = num_folds, shuffle=True)\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "num_epochs = 50\r\n",
        "\r\n",
        "fold_num = 1\r\n",
        "\r\n",
        "#Define the model and compile\r\n",
        "model = make_model()\r\n",
        "model.compile(optimizer=SGD(lr = 0.001, momentum = 0.9), metrics = 'accuracy', loss='binary_crossentropy')\r\n",
        "#Saving the weights before training as reset before each training\r\n",
        "model.save_weights('reset_model.h5')\r\n",
        "\r\n",
        "for train, test in kfold.split(X_tot, Y_tot):\r\n",
        "  '''Training the model and test it for every fold created \r\n",
        "  from the total original dataset'''\r\n",
        "  #Reset the model loading weights of untrained model\r\n",
        "  model.load_weights('reset_model.h5')\r\n",
        "  #Fitting the model using every folder but one as training\r\n",
        "  history = model.fit(\r\n",
        "          X_tot[train], Y_tot[train],\r\n",
        "          batch_size = batch_size,\r\n",
        "          verbose=0,\r\n",
        "          epochs = num_epochs)  \r\n",
        "  \r\n",
        "  #Evaluate the efficiency of the model\r\n",
        "  scores = model.evaluate(X_tot[test], Y_tot[test], verbose=0)\r\n",
        "  #Printing the results of the training\r\n",
        "  print('In folder {:d}: {} of {:.4f} - {} of {:.4f}'.format(fold_num,\r\n",
        "                                                          model.metrics_names[0],scores[0],\r\n",
        "                                                          model.metrics_names[1], scores[1] ))\r\n",
        "  \r\n",
        "\r\n",
        "  #Visualize loss and accuracy obtanined during the train for each fold  \r\n",
        "  plt.figure(fold_num)\r\n",
        "  plt.suptitle(f'In fold num. {fold_num}')\r\n",
        "  plt.subplot(1, 2, 1)\r\n",
        "  plt.plot(history.history['loss'])\r\n",
        "  plt.subplot(1, 2, 2)\r\n",
        "  plt.plot(history.history['accuracy'])\r\n",
        "\r\n",
        "  #Putting scores on to the corrisponding list to calculate the mean value ot them at the end\r\n",
        "  acc_per_fold.append(scores[1])\r\n",
        "  loss_per_fold.append(scores[0])\r\n",
        "  fold_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViYB3QK8chZJ"
      },
      "source": [
        "#Computing and printing average scores\r\n",
        "print('Average scores for all folds:')\r\n",
        "print(f'-- Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n",
        "#Calculare loss error as maximum value error\r\n",
        "err_loss = (max(loss_per_fold)-min(loss_per_fold))/2\r\n",
        "print(f'-- Loss: {np.mean(loss_per_fold)} +/- {err_loss}')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}