{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicocampo/CNN_prova/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfPNt06nZRfC"
      },
      "source": [
        "# Importing the dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycQRMl2Bg4Me"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqw3aYF1gDFD"
      },
      "source": [
        "# Reading and visualize the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqCZ72z2gCIH"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "import time\n",
        "\n",
        "\n",
        "logger = logging.getLogger('Mylogger')\n",
        "logger.setLevel(logging.INFO)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkOspN9xPlg8"
      },
      "source": [
        "PATH = 'gdrive/MyDrive/IMAGES/Mammography_micro'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKkkzEYlMqP"
      },
      "source": [
        "Imread restituisce un array 60 x 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bVKQicJt1gi"
      },
      "source": [
        "import multiprocessing as mp\r\n",
        "\r\n",
        "def parallel_read_img(image_path):\r\n",
        "  fnames = glob.glob(os.path.join(image_path, '*.pgm'))\r\n",
        "\r\n",
        "  pool = mp.Pool(processes=4)\r\n",
        "  results = pool.map_async(imread, fnames)\r\n",
        "\r\n",
        "  x = results.get()\r\n",
        "  x_np = np.array(x, dtype='float32')[..., np.newaxis]/255\r\n",
        "\r\n",
        "  print('Num images found = ', x_np.shape)\r\n",
        "  return x_np\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAREAlnsKhWk"
      },
      "source": [
        "start_time = time.time()\r\n",
        "\r\n",
        "labels = []\r\n",
        "\r\n",
        "image_path = os.path.join(PATH, 'Train/0')\r\n",
        "x0_train = parallel_read_img(image_path)\r\n",
        "labels += len(x0_train)*[0]\r\n",
        "\r\n",
        "image_path = os.path.join(PATH, 'Train/1')\r\n",
        "x1_train = parallel_read_img(image_path)\r\n",
        "labels += len(x1_train)*[1]\r\n",
        "\r\n",
        "x_train = np.concatenate((x0_train, x1_train), axis = 0)\r\n",
        "y_train = np.array(labels)\r\n",
        "\r\n",
        "print('x_train shape = ', x_train.shape)\r\n",
        "\r\n",
        "\r\n",
        "labels = []\r\n",
        "\r\n",
        "image_path = os.path.join(PATH, 'Test/0')\r\n",
        "x0_test = parallel_read_img(image_path)\r\n",
        "labels += len(x0_test)*[0]\r\n",
        "\r\n",
        "image_path = os.path.join(PATH, 'Test/1')\r\n",
        "x1_test = parallel_read_img(image_path)\r\n",
        "labels += len(x1_test)*[1]\r\n",
        "\r\n",
        "x_test = np.concatenate((x0_test, x1_test), axis = 0)\r\n",
        "y_test = np.array(labels)\r\n",
        "\r\n",
        "print('x_test shape = ', x_test.shape)\r\n",
        "\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "logging.info('Elapsed time = %.2f s', elapsed_time)\r\n",
        "print('Elapsed time = ', elapsed_time, 's')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfyUHHdW3Pa_"
      },
      "source": [
        "'''\r\n",
        "Visualize some images\r\n",
        "'''\r\n",
        "\r\n",
        "a = 25\r\n",
        "b = a+1\r\n",
        "\r\n",
        "i =1\r\n",
        "\r\n",
        "for n in range(a, b):\r\n",
        "  Im = x_test[n].squeeze()\r\n",
        "  print(Im.shape)\r\n",
        "  plt.figure(i)\r\n",
        "  imshow(Im)\r\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBkLQzhsmYaJ"
      },
      "source": [
        "#Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsWgaT6LmebC"
      },
      "source": [
        "import PIL\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re8kga5lmeMA"
      },
      "source": [
        "def convert_to_png(fname, dest_folder):\r\n",
        "  if not os.path.exists(dest_folder):\r\n",
        "    os.makedirs(dest_folder)\r\n",
        "  dest_fname = os.path.basename(fname).replace('.pgm', '.png')\r\n",
        "  dest_fname = os.path.join(dest_folder, dest_fname)\r\n",
        "  PIL.Image.open(fname).convert('L').save(dest_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XUCFASbmjLH"
      },
      "source": [
        "start_time = time.time()\r\n",
        "for data_path in [os.path.join(PATH, \"Train\"), os.path.join(PATH, \"Test\")]:\r\n",
        "  for path, folders, fnames in os.walk(data_path):\r\n",
        "    for fname in fnames:\r\n",
        "      abs_path = os.path.join(path, fname)\r\n",
        "      dest_folder = path.replace('Train', 'Train_png').replace('Test', 'Test_png')\r\n",
        "      convert_to_png(abs_path, dest_folder)\r\n",
        "logger.info('Elapsed time = %.2f s', time.time()-start_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm0582HRmr_h"
      },
      "source": [
        "#Data aumentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLXrCayXmrV3"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SayDNbnm3Fr"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\r\n",
        "\r\n",
        "Il FLOW_FROM_DIRECTORY prende in input il path della directory di arrivo e genera gruppi di immagini dando in output un ITERATORE (x, y) con y le labels e x le immagini con shape (batch_size, *target_size, channels)\r\n",
        "\r\n",
        "di default crea le imm in png\r\n",
        "\r\n",
        "*  batch_size (di default è 32) cioè il numero di immagini modificate generate per ogni immagine di X_train.\r\n",
        "\r\n",
        "*  subset = training o validation, funziona solo se c'è validation_split nel \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "ImageDataGenerator\r\n",
        "\r\n",
        "\r\n",
        "IMAGEDATAGENERATOR:\r\n",
        "Validation_split = 0.3 divide tutte le N immagini di x_train in: 70% train e 30% validazione e usa questo dataset nel model.fit \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKqhV2t8m_TS"
      },
      "source": [
        "Il.next() accede ad una immagine. train_gen.next()[0] ha shape = (32, 60, 60, 1) cioè per ogni immagine del dataset, lui genera 32 immagini modificate di dimensione 60x60 di colori grayscale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I49kI5enm4C_"
      },
      "source": [
        "path_to_png_data = os.path.join(PATH, \"Train_png\")\r\n",
        "\r\n",
        "img_width, img_height = (60, 60)\r\n",
        "\r\n",
        "aug_validation_split = 0.3\r\n",
        "\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "        rotation_range=40,\r\n",
        "        width_shift_range=0.2,\r\n",
        "        height_shift_range=0.2,\r\n",
        "        rescale=1./255,  #Rescale every pixel to have a value between 0 and 1\r\n",
        "        shear_range=0.2, #Stretches the image \r\n",
        "        zoom_range=0.2, \r\n",
        "        horizontal_flip=True,\r\n",
        "        fill_mode='reflect',\r\n",
        "        validation_split = aug_validation_split)  \r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_gen = train_datagen.flow_from_directory(\r\n",
        "    path_to_png_data,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    color_mode='grayscale', \r\n",
        "    class_mode='binary',\r\n",
        "    subset='training')\r\n",
        "\r\n",
        "val_gen = train_datagen.flow_from_directory(\r\n",
        "    path_to_png_data,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    color_mode='grayscale',\r\n",
        "    class_mode='binary',\r\n",
        "    subset='validation')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blz5VJ8pajXz"
      },
      "source": [
        "# Defining a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7plXV2WyaoGt"
      },
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dense, Flatten, InputLayer, Activation, Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY86U7qK2h8v"
      },
      "source": [
        "##CNN model\r\n",
        "Per ora è la miglire tra le 3 (con 100 epoche) per loss e validation sul dataset augmented"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBloTVdsaewM"
      },
      "source": [
        "def make_model(shape=(60, 60, 1)):\n",
        "  model = Sequential([\n",
        "      \n",
        "      Conv2D(50, (5,5), padding='same', input_shape=shape),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPool2D((2,2)),\n",
        "      \n",
        "      Conv2D(60, (3,3), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPool2D((2,2)),\n",
        "        \n",
        "      Conv2D(100, (3,3), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "\n",
        "      Conv2D(100, (3,3), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "\n",
        "      Conv2D(50, (4,4), padding='same'),\n",
        "      BatchNormalization(),\n",
        "      Activation('relu'),\n",
        "      MaxPool2D(2, 2),\n",
        "\n",
        "      Flatten(), \n",
        "      \n",
        "\n",
        "      Dense(1, activation='sigmoid')\n",
        "      \n",
        "  ])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXt999cLSEeT"
      },
      "source": [
        "#Fit model on originale dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUQjwzu90fsX"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\r\n",
        "\r\n",
        "\r\n",
        "early_stopping = EarlyStopping(\r\n",
        "    min_delta=0.001, # minimium amount of change to count as an improvement\r\n",
        "    patience=10, # how many epochs to wait before stopping\r\n",
        "    restore_best_weights=True,\r\n",
        ")\r\n",
        "\r\n",
        "reduce_lr = ReduceLROnPlateau(\r\n",
        "    monitor='loss', \r\n",
        "    factor=0.5,\r\n",
        "    patience = 5,\r\n",
        "    min_lr=0.00001\r\n",
        "\r\n",
        ")\r\n",
        "\r\n",
        "checkpoint = ModelCheckpoint(\r\n",
        "    \"model-{epoch:02d}-{val_accuracy:.2f}.hdf5\", \r\n",
        "    monitor='val_accuracy', \r\n",
        "    verbose=1,\r\n",
        "    save_best_only=True,\r\n",
        "    save_weights_only=False,\r\n",
        "    mode='auto', save_freq='epoch')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPh3ewyPn1bR"
      },
      "source": [
        "from keras.optimizers import SGD\r\n",
        "\r\n",
        "model = make_model()\r\n",
        "\r\n",
        "model.compile(optimizer=SGD(lr = 0.001, momentum = 0.9), metrics = 'accuracy', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH25BWCqfbGM"
      },
      "source": [
        "history = model.fit(x_train, y_train, \r\n",
        "                    validation_split=0.3, \r\n",
        "                    epochs=100, \r\n",
        "                    batch_size=30, \r\n",
        "                    shuffle=True, \r\n",
        "                    callbacks = [checkpoint],\r\n",
        "                    verbose=1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ConM7Babe9VD"
      },
      "source": [
        "model.save(os.path.join(PATH, 'model.hdf5'))\r\n",
        "model.evaluate(x_test, y_test)  # returns 'loss' and 'metrics' (accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS3iyYXqoda2"
      },
      "source": [
        "# Fit model on augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avE0zljglFk5"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"model_augmented.{epoch:02d}-{val_accuracy:.2f}.h5\", \n",
        "    monitor='val_accuracy', \n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto', save_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_CujADtu11l"
      },
      "source": [
        "STEPS_PER_EPOCH: Definisce il numero di immagini da usare ad ogni epoca, è utile quando il numero delle immagini non è fisso perchè vengono generate potenzialmente infiniti samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFlLwmgSZvKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df95a1a-ef33-428a-a8ce-f615596d5fe5"
      },
      "source": [
        "Tot_train_imgs = len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7yiPz99j_Fw"
      },
      "source": [
        "model = make_model()\n",
        "\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.0005, momentum=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size=32\n",
        "steps_per_epoch = int(Tot_train_imgs * (1- aug_validation_split))\n",
        "validation_steps = int(Tot_train_imgs * aug_validation_split)\n",
        "\n",
        "logger.info('Steps per epoch = %d', steps_per_epoch)\n",
        "logger.info('Val steps = %d', validation_steps)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=steps_per_epoch // batch_size,\n",
        "        epochs=100,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps= validation_steps // batch_size,\n",
        "        verbose=1,\n",
        "        callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpIDYyYf29HD"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7sjHFpGpPtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e7d564-46b5-4c13-e4f9-8b2c70dee599"
      },
      "source": [
        "model.save(os.path.join(PATH, 'model_augmented.hdf5'))\r\n",
        "\r\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46187886595726013, 0.7955112457275391]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziJxv3y8fYoo"
      },
      "source": [
        "# Comparing the performances of the two models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u8dNJW0fLd3"
      },
      "source": [
        "from keras.models import load_model\n",
        "aug_model = load_model(os.path.join(PATH, 'model_augmented.hdf5'))\n",
        "noaug_model = load_model(os.path.join(PATH, 'model.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoMbhMQMf_E9"
      },
      "source": [
        "noaug_model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "aug_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZBgQ-PwuSFq"
      },
      "source": [
        "#Implement a cross-validation test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md5HpjB_uzIJ"
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhshIa47uU-x"
      },
      "source": [
        "# Define per-fold score arrays\r\n",
        "acc_per_fold = []\r\n",
        "loss_per_fold = []\r\n",
        "\r\n",
        "# Merge train and test in a single array\r\n",
        "X_tot = np.concatenate((x_train, x_test), axis=0)\r\n",
        "Y_tot = np.concatenate((y_train, y_test), axis=0)\r\n",
        "\r\n",
        "\r\n",
        "num_folds = 10\r\n",
        "\r\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "num_epochs = 30\r\n",
        "\r\n",
        "fold_nro = 1\r\n",
        "\r\n",
        "for train, test in kfold.split(X_tot, Y_tot):\r\n",
        "  print('In fold n. ', fold_nro)\r\n",
        "  model = make_model()\r\n",
        "\r\n",
        "  model.compile(optimizer=SGD(lr = 0.001, momentum = 0.9), metrics = 'accuracy', loss='binary_crossentropy')\r\n",
        "\r\n",
        "  history = model.fit(\r\n",
        "          X_tot[train], Y_tot[train],\r\n",
        "          batch_size = batch_size,\r\n",
        "          verbose=0,\r\n",
        "          epochs = num_epochs)  \r\n",
        "  \r\n",
        "  scores = model.evaluate(X_tot[test], Y_tot[test], verbose=0)\r\n",
        "\r\n",
        "  print(f'Score for fold {fold_nro}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\r\n",
        "  acc_per_fold.append(scores[1])\r\n",
        "  loss_per_fold.append(scores[0])\r\n",
        "  fold_nro += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC2AHLkUjOgn"
      },
      "source": [
        "Computing average scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViYB3QK8chZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601406d4-b337-4ea9-c847-b9eb719e00bc"
      },
      "source": [
        "print('Score per fold')\r\n",
        "for i in range(0, len(acc_per_fold)):\r\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\r\n",
        "\r\n",
        "print('\\n')\r\n",
        "print('Average scores for all folds:')\r\n",
        "print(f'-- Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n",
        "print(f'-- Loss: {np.mean(loss_per_fold)}')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score per fold\n",
            "> Fold 1 - Loss: 0.27033376693725586 - Accuracy: 0.8999999761581421%\n",
            "> Fold 2 - Loss: 0.23841264843940735 - Accuracy: 0.8999999761581421%\n",
            "> Fold 3 - Loss: 0.7847806215286255 - Accuracy: 0.762499988079071%\n",
            "> Fold 4 - Loss: 0.15519122779369354 - Accuracy: 0.9375%\n",
            "> Fold 5 - Loss: 0.18688325583934784 - Accuracy: 0.8999999761581421%\n",
            "> Fold 6 - Loss: 0.2376764565706253 - Accuracy: 0.9125000238418579%\n",
            "> Fold 7 - Loss: 0.3531305193901062 - Accuracy: 0.875%\n",
            "> Fold 8 - Loss: 0.31873416900634766 - Accuracy: 0.9113923907279968%\n",
            "> Fold 9 - Loss: 0.32309162616729736 - Accuracy: 0.8607594966888428%\n",
            "> Fold 10 - Loss: 0.24024492502212524 - Accuracy: 0.8987341523170471%\n",
            "\n",
            "\n",
            "Average scores for all folds:\n",
            "-- Accuracy: 0.8858385980129242 (+- 0.04556260182307142)\n",
            "-- Loss: 0.31084792166948316\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}